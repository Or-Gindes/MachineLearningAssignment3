{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Or-Gindes/MachineLearningAssignment3/blob/master/Assignment3_part2_VGG19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PreProcessing**"
      ],
      "metadata": {
        "id": "p7_szzN6eDkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "lauDpmNX2T4O",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e72f41fa-c9f4-485b-b6b0-68abab545cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=89126523b550d89c7ffdf5c09514421a963d8b276c7ce9af2264f2dd151a5a25\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.25.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.applications import VGG19, vgg19\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import scipy.io\n",
        "import tarfile\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "import tarfile\n",
        "import io\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "seed = 123"
      ],
      "metadata": {
        "id": "9XCHWhx-RZHV",
        "execution": {
          "iopub.status.busy": "2023-06-15T17:47:32.203810Z",
          "iopub.execute_input": "2023-06-15T17:47:32.204305Z",
          "iopub.status.idle": "2023-06-15T17:47:42.232689Z",
          "shell.execute_reply.started": "2023-06-15T17:47:32.204261Z",
          "shell.execute_reply": "2023-06-15T17:47:42.231633Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get images & labels and extract in current folder\n",
        "dataset = \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\"\n",
        "labels = \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat\"\n",
        "urlretrieve(dataset, dataset.rsplit('/', 1)[-1])\n",
        "urlretrieve(labels, labels.rsplit('/', 1)[-1])\n",
        "\n",
        "tgz_file = dataset.rsplit('/', 1)[-1]\n",
        "with tarfile.open(tgz_file, 'r:gz') as file:\n",
        "    # Extract all files to the specified directory\n",
        "    file.extractall('.')"
      ],
      "metadata": {
        "id": "VUDfv4j2spdh",
        "execution": {
          "iopub.status.busy": "2023-06-15T17:47:44.824371Z",
          "iopub.execute_input": "2023-06-15T17:47:44.825111Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image labels into y and count unique classes\n",
        "mat = scipy.io.loadmat(labels.rsplit('/', 1)[-1])\n",
        "y = pd.Series(mat['labels'][0])\n",
        "unique_labels = y.unique()\n",
        "print(f\"Number of unique classes: {len(unique_labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUmoOIT1s-8n",
        "outputId": "35facde0-5778-4e9f-d0a0-10429d3dac76",
        "execution": {
          "iopub.status.busy": "2023-06-14T21:07:20.115081Z",
          "iopub.execute_input": "2023-06-14T21:07:20.115812Z",
          "iopub.status.idle": "2023-06-14T21:07:20.133120Z",
          "shell.execute_reply.started": "2023-06-14T21:07:20.115766Z",
          "shell.execute_reply": "2023-06-14T21:07:20.131961Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique classes: 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dataframe for the ImageDataGenerator.flow_from_dataframe pipeline\n",
        "data_dir = os.path.join(os.getcwd(), 'jpg')\n",
        "print(f\"data directory: {data_dir}\")\n",
        "df = pd.DataFrame({\"filename\": sorted(os.listdir(data_dir)),  \"class\": y.astype(str)})#, 'label': to_categorical(y-1).tolist()})\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "9807Mt37qi0R",
        "outputId": "46a1f5f0-d955-4317-9eb0-a7cd13ed5d6b",
        "execution": {
          "iopub.status.busy": "2023-06-14T21:07:46.942954Z",
          "iopub.execute_input": "2023-06-14T21:07:46.943329Z",
          "iopub.status.idle": "2023-06-14T21:07:46.983276Z",
          "shell.execute_reply.started": "2023-06-14T21:07:46.943291Z",
          "shell.execute_reply": "2023-06-14T21:07:46.982420Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data directory: /content/jpg\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          filename class\n",
              "0  image_00001.jpg    77\n",
              "1  image_00002.jpg    77\n",
              "2  image_00003.jpg    77\n",
              "3  image_00004.jpg    77\n",
              "4  image_00005.jpg    77"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-674fbffa-bc11-4791-9e71-071de31f2d0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image_00001.jpg</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image_00002.jpg</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image_00003.jpg</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image_00004.jpg</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image_00005.jpg</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-674fbffa-bc11-4791-9e71-071de31f2d0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-674fbffa-bc11-4791-9e71-071de31f2d0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-674fbffa-bc11-4791-9e71-071de31f2d0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_val_test_split(df, label_col='class', seed=123):\n",
        "  \"\"\"\n",
        "  Split DataFrame df to train/validation/test dataframes with 50%/25%/25% ratio\n",
        "  \"\"\"\n",
        "  # Divide dataset randomly into train, validation, and test sets\n",
        "  train_df, val_test_df = train_test_split(df, stratify=df[label_col],\n",
        "                                          test_size=0.5,\n",
        "                                          random_state=seed,\n",
        "                                          shuffle=True)\n",
        "\n",
        "  val_df, test_df = train_test_split(val_test_df,\n",
        "                                    stratify=val_test_df[label_col],\n",
        "                                    test_size=0.5,\n",
        "                                    random_state=seed,\n",
        "                                    shuffle=True)\n",
        "\n",
        "  return train_df, val_df, test_df"
      ],
      "metadata": {
        "id": "LpnVmoECqota",
        "execution": {
          "iopub.status.busy": "2023-06-14T21:07:51.241253Z",
          "iopub.execute_input": "2023-06-14T21:07:51.242214Z",
          "iopub.status.idle": "2023-06-14T21:07:51.249471Z",
          "shell.execute_reply.started": "2023-06-14T21:07:51.242171Z",
          "shell.execute_reply": "2023-06-14T21:07:51.248560Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import random\n",
        "\n",
        "def add_noise_with_func(img):\n",
        "    '''Add random noise to an image'''\n",
        "    VARIABILITY = 50\n",
        "    deviation = VARIABILITY*random()\n",
        "    noise = np.random.normal(0, deviation, img.shape)\n",
        "    img += noise\n",
        "    np.clip(img, 0., 255.)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "def get_data_generators(df, data_dir, preprocess_func, x_col='filename', y_col='class',\n",
        "                        input_shape=(224, 224), batch_size=32, seed=123):\n",
        "  \"\"\"\n",
        "  Accepts dataframe of image file names, folder with images, preprocessing function\n",
        "  and other optional parameters and returns train/validation/test data generators\n",
        "  \"\"\"\n",
        "  train_df, val_df, test_df = get_train_val_test_split(df, y_col, seed)\n",
        "\n",
        "  # Define image preprocessing and augmentation options\n",
        "  datagen = ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_func\n",
        "      # shear_range=0.2,\n",
        "      # zoom_range=0.2,\n",
        "      # horizontal_flip=True\n",
        "  )\n",
        "\n",
        "  # Define Image generator for each of train/validation/test set\n",
        "  print(\"Training set:\")\n",
        "  train_generator = datagen.flow_from_dataframe(\n",
        "      train_df,\n",
        "      directory=data_dir,\n",
        "      x_col=x_col,\n",
        "      y_col=y_col,\n",
        "      target_size=input_shape,\n",
        "      batch_size=batch_size,\n",
        "      class_mode=\"categorical\",\n",
        "      shuffle=True,\n",
        "      seed=seed\n",
        "  )\n",
        "  # Batch size isn't needed for val and test generators because we want to\n",
        "  # evaluated score for entire set\n",
        "  print(\"Validation set:\")\n",
        "  val_generator = datagen.flow_from_dataframe(\n",
        "      val_df,\n",
        "      directory=data_dir,\n",
        "      x_col=x_col,\n",
        "      y_col=y_col,\n",
        "      target_size=input_shape,\n",
        "      class_mode=\"categorical\",\n",
        "      shuffle=False,\n",
        "      seed=seed\n",
        "  )\n",
        "  print(\"Test set:\")\n",
        "  test_generator = datagen.flow_from_dataframe(\n",
        "      test_df,\n",
        "      directory=data_dir,\n",
        "      x_col=x_col,\n",
        "      y_col=y_col,\n",
        "      target_size=input_shape,\n",
        "      class_mode=\"categorical\",\n",
        "      shuffle=False,\n",
        "      seed=seed\n",
        "  )\n",
        "  return train_generator, val_generator, test_generator"
      ],
      "metadata": {
        "id": "mHVuFEYGq3p2",
        "execution": {
          "iopub.status.busy": "2023-06-14T21:07:58.217845Z",
          "iopub.execute_input": "2023-06-14T21:07:58.218192Z",
          "iopub.status.idle": "2023-06-14T21:07:58.227722Z",
          "shell.execute_reply.started": "2023-06-14T21:07:58.218164Z",
          "shell.execute_reply": "2023-06-14T21:07:58.226689Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_base_model():\n",
        "  # Define base model from VGG10 pre-trained on imagenet\n",
        "  base_model = VGG19(weights=\"imagenet\", include_top=False,\n",
        "                     input_shape=(224, 224, 3))\n",
        "  return base_model\n",
        "\n",
        "def get_top_model(y):\n",
        "  # Define a new top model - output layer should have nodes same as number of labels in y\n",
        "  n_classes = len(y.unique())\n",
        "\n",
        "  top_model = Sequential()\n",
        "  top_model.add(GlobalAveragePooling2D())\n",
        "  top_model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  # top_model = Sequential()\n",
        "  # top_model.add(Dropout(0.2))\n",
        "  # top_model.add(GlobalAveragePooling2D())\n",
        "  # top_model.add(Dense(n_classes, activation='softmax'))\n",
        "  return top_model\n",
        "\n",
        "def train_and_evaluate(df, data_dir, preprocess_func, model_name, config,\n",
        "                       epochs=20, n=2):\n",
        "  \"\"\"\n",
        "  Compile a model from a vgg19 base model and a top model\n",
        "  Train the composite model with given optimizer for given number of epochs.\n",
        "  Evaluate the model and repeat n times to generate accurate evaluation\n",
        "  Log results in wandb\n",
        "  \"\"\"\n",
        "  base_seed = 42\n",
        "  seed_gen = iter(range(base_seed, base_seed*n + 1, base_seed))\n",
        "  histories = []\n",
        "  test_results = {'Accuracy': [], 'Loss': []}\n",
        "  for i in range(n):\n",
        "    print(f\"\\nTraining-Evaluation cycle - {i+1} - Model: {model_name}\")\n",
        "\n",
        "    # Get an instance of base and top models\n",
        "    base_model = get_base_model()\n",
        "    top_model = get_top_model(df['class'])\n",
        "\n",
        "    # Get the data generators\n",
        "    train_generator, validation_generator, test_generator = get_data_generators(df, data_dir, preprocess_func, seed=next(seed_gen))\n",
        "\n",
        "    # Freeze base_model layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Combine the base_model with new top model\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(top_model)\n",
        "\n",
        "    model.compile(optimizer=tensorflow.keras.optimizers.RMSprop(weight_decay=0.0001, centered=True),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', restore_best_weights=True)\n",
        "\n",
        "    print(\"\\nTraining:\")\n",
        "    history = model.fit(train_generator, epochs=epochs, callbacks=[early_stopping],\n",
        "                        validation_data=validation_generator, verbose=1)\n",
        "    histories.append(history)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    print(\"\\nEvaluating:\")\n",
        "    loss, accuracy = model.evaluate(test_generator)\n",
        "    test_results['Accuracy'].append(accuracy)\n",
        "    test_results['Loss'].append(loss)\n",
        "\n",
        "    print(\"Test Loss:\", round(loss, 3))\n",
        "    print(f\"Test Accuracy: {round(accuracy * 100, 3)}%\")\n",
        "\n",
        "  evaluate(model_name, epochs, test_results, histories, config)\n",
        "  return\n",
        "\n",
        "def element_wise_avg(nested_lists):\n",
        "  return [sum(elements) / len(elements) for elements in zip(*nested_lists)]\n",
        "\n",
        "def evaluate(name, epochs, test_results, histories, config):\n",
        "  wandb.init(project='MachineLearning_Assignment3',\n",
        "            name=name,\n",
        "            config=config)\n",
        "\n",
        "  acc =  round(np.mean(test_results[\"Accuracy\"]), 3)\n",
        "  loss = round(np.mean(test_results[\"Loss\"]), 3)\n",
        "  wandb.log({\"test_accuracy\": acc, \"test_loss\": loss})\n",
        "\n",
        "  avg_loss = element_wise_avg([history.history[\"loss\"] for history in histories])\n",
        "  avg_val_loss = element_wise_avg([history.history[\"val_loss\"] for history in histories])\n",
        "  avg_accuracy = element_wise_avg([history.history[\"accuracy\"] for history in histories])\n",
        "  avg_val_accuracy = element_wise_avg([history.history[\"val_accuracy\"] for history in histories])\n",
        "  wandb.log({\"train_accuracy\": np.max(avg_accuracy), \"train_loss\": np.min(avg_loss)})\n",
        "  wandb.log({\"validation_accuracy\": np.max(avg_val_accuracy), \"validation_loss\": np.min(avg_val_loss)})\n",
        "  wandb.log({\"epochs\": max([history.params['epochs'] for history in histories])})\n",
        "\n",
        "  fig, axs = plt.subplots(figsize=(10, 5), ncols=2)\n",
        "  axs = axs.ravel()\n",
        "  axs[0].plot(avg_loss, label=\"Training\")\n",
        "  axs[0].plot(avg_val_loss, label=\"Validation\")\n",
        "  axs[0].set_title(f\"{name}_Loss\")\n",
        "  axs[0].legend(loc='upper right')\n",
        "\n",
        "  axs[1].plot(avg_accuracy, label=\"Training\")\n",
        "  axs[1].plot(avg_val_accuracy, label=\"Validation\")\n",
        "  axs[1].set_title(f\"{name}_Accuracy\")\n",
        "  axs[1].legend(loc='lower right')\n",
        "\n",
        "  fig.show()\n",
        "  wandb.log({f\"{name}_accuracy_loss\": fig})\n",
        "\n",
        "  wandb.finish()\n"
      ],
      "metadata": {
        "id": "SzmZcqjIhPDZ",
        "execution": {
          "iopub.status.busy": "2023-06-14T21:13:28.943925Z",
          "iopub.execute_input": "2023-06-14T21:13:28.944322Z",
          "iopub.status.idle": "2023-06-14T21:13:28.967328Z",
          "shell.execute_reply.started": "2023-06-14T21:13:28.944263Z",
          "shell.execute_reply": "2023-06-14T21:13:28.966425Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VGG19**"
      ],
      "metadata": {
        "id": "A9WYrjy6dsXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing for this model is accomplished with the preprocess_input function which converts the input images from RGB to BGR and zero-centers each color channel with respect to the ImageNet dataset, without scaling the image. The images are read with target_size 224x224 which is the input side of the model"
      ],
      "metadata": {
        "id": "8WUVlSlTLCKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained VGG19 model without the top (classification) layers\n",
        "# to observe the structure of the model\n",
        "vgg_base_model = VGG19(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "vgg_base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdhdlmzVttR4",
        "outputId": "60372341-009e-466f-bbe0-c5d5291ad4fd",
        "execution": {
          "iopub.status.busy": "2023-06-14T21:11:46.007171Z",
          "iopub.execute_input": "2023-06-14T21:11:46.007529Z",
          "iopub.status.idle": "2023-06-14T21:11:53.164256Z",
          "shell.execute_reply.started": "2023-06-14T21:11:46.007501Z",
          "shell.execute_reply": "2023-06-14T21:11:53.163555Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to tune the hyperparameters of the model its required to repeat the splitting process of the dataset a number of times, training and evaluating the model with each split to get an accurate evaluation"
      ],
      "metadata": {
        "id": "KuAoqx0rghzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "config = {\"base_model\": \"VGG19\", \"top_model\": \"AvgPooling+Dense\",\n",
        "                    \"Preprocessing\": \"vgg19_preprocess_input\",\n",
        "                    \"optimizer\": \"RMSprop_tuned\", \"Epochs\": epochs}\n",
        "\n",
        "train_and_evaluate(df, data_dir, model_name=\"VGG19_RMSProp_tuned\", config=config,\n",
        "                   preprocess_func=vgg19.preprocess_input, epochs=epochs, n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhjeXvSHinWs",
        "outputId": "cc8e49f7-24a4-4fcf-bbe5-5d69e06eb550",
        "execution": {
          "iopub.status.busy": "2023-06-14T21:14:34.731662Z",
          "iopub.execute_input": "2023-06-14T21:14:34.732022Z",
          "iopub.status.idle": "2023-06-15T05:11:19.185793Z",
          "shell.execute_reply.started": "2023-06-14T21:14:34.731993Z",
          "shell.execute_reply": "2023-06-15T05:11:19.184648Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training-Evaluation cycle - 1 - Model: VGG19_RMSProp_tuned\n",
            "Training set:\n",
            "Found 4094 validated image filenames belonging to 102 classes.\n",
            "Validation set:\n",
            "Found 2047 validated image filenames belonging to 102 classes.\n",
            "Test set:\n",
            "Found 2048 validated image filenames belonging to 102 classes.\n",
            "\n",
            "Training:\n",
            "Epoch 1/50\n",
            "128/128 [==============================] - 49s 373ms/step - loss: 5.1678 - accuracy: 0.2157 - val_loss: 2.3915 - val_accuracy: 0.4651\n",
            "Epoch 2/50\n",
            "128/128 [==============================] - 48s 379ms/step - loss: 1.4300 - accuracy: 0.6448 - val_loss: 1.2830 - val_accuracy: 0.6771\n",
            "Epoch 3/50\n",
            "128/128 [==============================] - 48s 376ms/step - loss: 0.6644 - accuracy: 0.8149 - val_loss: 0.9518 - val_accuracy: 0.7592\n",
            "Epoch 4/50\n",
            "128/128 [==============================] - 48s 376ms/step - loss: 0.3718 - accuracy: 0.9006 - val_loss: 0.7862 - val_accuracy: 0.7909\n",
            "Epoch 5/50\n",
            "128/128 [==============================] - 49s 384ms/step - loss: 0.2314 - accuracy: 0.9387 - val_loss: 0.7462 - val_accuracy: 0.8139\n",
            "Epoch 6/50\n",
            "128/128 [==============================] - 48s 373ms/step - loss: 0.1515 - accuracy: 0.9641 - val_loss: 0.6942 - val_accuracy: 0.8256\n",
            "Epoch 7/50\n",
            "128/128 [==============================] - 101s 793ms/step - loss: 0.1042 - accuracy: 0.9753 - val_loss: 0.6643 - val_accuracy: 0.8363\n",
            "Epoch 8/50\n",
            "128/128 [==============================] - 49s 384ms/step - loss: 0.0679 - accuracy: 0.9836 - val_loss: 0.6553 - val_accuracy: 0.8398\n",
            "Epoch 9/50\n",
            "128/128 [==============================] - 47s 371ms/step - loss: 0.0491 - accuracy: 0.9885 - val_loss: 0.6841 - val_accuracy: 0.8432\n",
            "Epoch 10/50\n",
            "128/128 [==============================] - 49s 383ms/step - loss: 0.0345 - accuracy: 0.9939 - val_loss: 0.6521 - val_accuracy: 0.8549\n",
            "Epoch 11/50\n",
            "128/128 [==============================] - 53s 417ms/step - loss: 0.0242 - accuracy: 0.9958 - val_loss: 0.6841 - val_accuracy: 0.8456\n",
            "Epoch 12/50\n",
            "128/128 [==============================] - 53s 411ms/step - loss: 0.0183 - accuracy: 0.9973 - val_loss: 0.6816 - val_accuracy: 0.8500\n",
            "Epoch 13/50\n",
            "128/128 [==============================] - 48s 372ms/step - loss: 0.0133 - accuracy: 0.9983 - val_loss: 0.6915 - val_accuracy: 0.8544\n",
            "Epoch 14/50\n",
            "128/128 [==============================] - 48s 379ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.6916 - val_accuracy: 0.8534\n",
            "Epoch 15/50\n",
            "128/128 [==============================] - 48s 378ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 0.6958 - val_accuracy: 0.8564\n",
            "Epoch 16/50\n",
            "128/128 [==============================] - 50s 393ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.7067 - val_accuracy: 0.8578\n",
            "Epoch 17/50\n",
            "128/128 [==============================] - 53s 413ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.7004 - val_accuracy: 0.8569\n",
            "Epoch 18/50\n",
            "128/128 [==============================] - 53s 413ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.6950 - val_accuracy: 0.8613\n",
            "Epoch 19/50\n",
            "128/128 [==============================] - 53s 414ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.6980 - val_accuracy: 0.8632\n",
            "Epoch 20/50\n",
            "128/128 [==============================] - 50s 388ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.7106 - val_accuracy: 0.8622\n",
            "Epoch 21/50\n",
            "128/128 [==============================] - 49s 381ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.7066 - val_accuracy: 0.8598\n",
            "Epoch 22/50\n",
            "128/128 [==============================] - 49s 385ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.7287 - val_accuracy: 0.8588\n",
            "Epoch 23/50\n",
            "128/128 [==============================] - 48s 374ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.7098 - val_accuracy: 0.8613\n",
            "Epoch 24/50\n",
            "128/128 [==============================] - 49s 380ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.7146 - val_accuracy: 0.8627\n",
            "\n",
            "Evaluating:\n",
            "64/64 [==============================] - 17s 263ms/step - loss: 0.6529 - accuracy: 0.8706\n",
            "Test Loss: 0.653\n",
            "Test Accuracy: 87.061%\n",
            "\n",
            "Training-Evaluation cycle - 2 - Model: VGG19_RMSProp_tuned\n",
            "Training set:\n",
            "Found 4094 validated image filenames belonging to 102 classes.\n",
            "Validation set:\n",
            "Found 2047 validated image filenames belonging to 102 classes.\n",
            "Test set:\n",
            "Found 2048 validated image filenames belonging to 102 classes.\n",
            "\n",
            "Training:\n",
            "Epoch 1/50\n",
            "128/128 [==============================] - 50s 381ms/step - loss: 5.2448 - accuracy: 0.2088 - val_loss: 2.4877 - val_accuracy: 0.4416\n",
            "Epoch 2/50\n",
            "128/128 [==============================] - 48s 373ms/step - loss: 1.4782 - accuracy: 0.6375 - val_loss: 1.2649 - val_accuracy: 0.6702\n",
            "Epoch 3/50\n",
            "128/128 [==============================] - 48s 378ms/step - loss: 0.6981 - accuracy: 0.8131 - val_loss: 0.9057 - val_accuracy: 0.7577\n",
            "Epoch 4/50\n",
            "128/128 [==============================] - 49s 379ms/step - loss: 0.3975 - accuracy: 0.8918 - val_loss: 0.7874 - val_accuracy: 0.7963\n",
            "Epoch 5/50\n",
            "128/128 [==============================] - 49s 386ms/step - loss: 0.2458 - accuracy: 0.9331 - val_loss: 0.6894 - val_accuracy: 0.8183\n",
            "Epoch 6/50\n",
            "128/128 [==============================] - 48s 375ms/step - loss: 0.1619 - accuracy: 0.9599 - val_loss: 0.6486 - val_accuracy: 0.8407\n",
            "Epoch 7/50\n",
            "128/128 [==============================] - 48s 378ms/step - loss: 0.1054 - accuracy: 0.9753 - val_loss: 0.6125 - val_accuracy: 0.8442\n",
            "Epoch 8/50\n",
            "128/128 [==============================] - 48s 375ms/step - loss: 0.0733 - accuracy: 0.9846 - val_loss: 0.6220 - val_accuracy: 0.8373\n",
            "Epoch 9/50\n",
            "128/128 [==============================] - 48s 377ms/step - loss: 0.0527 - accuracy: 0.9885 - val_loss: 0.5787 - val_accuracy: 0.8486\n",
            "Epoch 10/50\n",
            "128/128 [==============================] - 47s 371ms/step - loss: 0.0368 - accuracy: 0.9934 - val_loss: 0.6063 - val_accuracy: 0.8515\n",
            "Epoch 11/50\n",
            "128/128 [==============================] - 49s 385ms/step - loss: 0.0253 - accuracy: 0.9966 - val_loss: 0.6061 - val_accuracy: 0.8598\n",
            "Epoch 12/50\n",
            "128/128 [==============================] - 48s 373ms/step - loss: 0.0195 - accuracy: 0.9976 - val_loss: 0.5832 - val_accuracy: 0.8622\n",
            "Epoch 13/50\n",
            "128/128 [==============================] - 49s 380ms/step - loss: 0.0128 - accuracy: 0.9990 - val_loss: 0.5620 - val_accuracy: 0.8647\n",
            "Epoch 14/50\n",
            "128/128 [==============================] - 49s 380ms/step - loss: 0.0093 - accuracy: 0.9995 - val_loss: 0.5750 - val_accuracy: 0.8642\n",
            "Epoch 15/50\n",
            "128/128 [==============================] - 48s 376ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.5697 - val_accuracy: 0.8705\n",
            "Epoch 16/50\n",
            "128/128 [==============================] - 47s 371ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.5798 - val_accuracy: 0.8696\n",
            "Epoch 17/50\n",
            "128/128 [==============================] - 48s 376ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5764 - val_accuracy: 0.8745\n",
            "Epoch 18/50\n",
            "128/128 [==============================] - 48s 377ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5843 - val_accuracy: 0.8710\n",
            "Epoch 19/50\n",
            "128/128 [==============================] - 48s 376ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.8686\n",
            "Epoch 20/50\n",
            "128/128 [==============================] - 47s 370ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5886 - val_accuracy: 0.8720\n",
            "Epoch 21/50\n",
            "128/128 [==============================] - 50s 389ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.8740\n",
            "Epoch 22/50\n",
            "128/128 [==============================] - 48s 372ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.8774\n",
            "Epoch 23/50\n",
            "128/128 [==============================] - 48s 377ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.8735\n",
            "Epoch 24/50\n",
            "128/128 [==============================] - 48s 371ms/step - loss: 8.9460e-04 - accuracy: 1.0000 - val_loss: 0.5887 - val_accuracy: 0.8788\n",
            "Epoch 25/50\n",
            "128/128 [==============================] - 50s 388ms/step - loss: 7.8208e-04 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.8740\n",
            "Epoch 26/50\n",
            "128/128 [==============================] - 48s 377ms/step - loss: 6.7415e-04 - accuracy: 1.0000 - val_loss: 0.5972 - val_accuracy: 0.8730\n",
            "Epoch 27/50\n",
            "128/128 [==============================] - 52s 409ms/step - loss: 6.1815e-04 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.8788\n",
            "Epoch 28/50\n",
            "128/128 [==============================] - 49s 382ms/step - loss: 5.2495e-04 - accuracy: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.8784\n",
            "Epoch 29/50\n",
            "  5/128 [>.............................] - ETA: 38s - loss: 3.3679e-04 - accuracy: 1.0000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JLooqc40zh-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}